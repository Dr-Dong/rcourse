<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title>Module 6: Intro to Bayesian Methods in R</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/flatly.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #0000ff; } /* Keyword */
code > span.ch { color: #008080; } /* Char */
code > span.st { color: #008080; } /* String */
code > span.co { color: #008000; } /* Comment */
code > span.ot { color: #ff4000; } /* Other */
code > span.al { color: #ff0000; } /* Alert */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #008000; font-weight: bold; } /* Warning */
code > span.cn { } /* Constant */
code > span.sc { color: #008080; } /* SpecialChar */
code > span.vs { color: #008080; } /* VerbatimString */
code > span.ss { color: #008080; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { } /* Variable */
code > span.cf { color: #0000ff; } /* ControlFlow */
code > span.op { } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #ff4000; } /* Preprocessor */
code > span.do { color: #008000; } /* Documentation */
code > span.an { color: #008000; } /* Annotation */
code > span.cv { color: #008000; } /* CommentVar */
code > span.at { } /* Attribute */
code > span.in { color: #008000; } /* Information */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' || rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 60px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h2 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h3 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h4 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h5 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h6 {
  padding-top: 65px;
  margin-top: -65px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<div class="container-fluid main-container">

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->



<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3,h4,h5",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Data Analysis in R</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Overview
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="calendar.html">Schedule</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Modules
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="module1.html">M1:  Base R</a>
    </li>
    <li>
      <a href="module2.html">M2: Tidyverse Data Preparation</a>
    </li>
    <li>
      <a href="module3.html">M3: Programming, joining data, and more</a>
    </li>
    <li>
      <a href="module4.html">M4: Project Management and Dynamic Documents</a>
    </li>
    <li>
      <a href="module5.html">M5: Regression Modelling and Data Visualization</a>
    </li>
    <li>
      <a href="module6.html">M6: Intro to Bayesian Methods</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Learning Resources
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="https://www.datacamp.com/">DataCamp</a>
    </li>
    <li>
      <a href="https://www.rstudio.com/resources/cheatsheets/">RStudio Cheat Sheets</a>
    </li>
    <li>
      <a href="https://www.statmethods.net/">Quick-R</a>
    </li>
    <li>
      <a href="https://stackoverflow.com/">StackOverflow</a>
    </li>
    <li>
      <a href="https://www.r-bloggers.com/">R-Bloggers</a>
    </li>
    <li>
      <a href="http://r4ds.had.co.nz/">R for Data Science Online Book</a>
    </li>
    <li>
      <a href="https://style.tidyverse.org/">R Style Guide</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Downloads
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Basic R Software</li>
    <li>
      <a href="https://cran.r-project.org/">R</a>
    </li>
    <li>
      <a href="https://www.rstudio.com/">RStudio</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Latex</li>
    <li>
      <a href="https://miktex.org/download">MiKTex (Windows)</a>
    </li>
    <li>
      <a href="http://www.tug.org/mactex/mactex-download.html">MacTex (Mac)</a>
    </li>
    <li>
      <a href="https://www.tug.org/texlive/debian.html">TeX Live (Linux)</a>
    </li>
    <li>
      <a href="https://www.sumatrapdfreader.org/free-pdf-reader.html">Sumatra PDF (Windows)</a>
    </li>
    <li>
      <a href="https://skim-app.sourceforge.io/">Skim PDF (Mac)</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Version Control</li>
    <li>
      <a href="https://git-scm.com/downloads">Git</a>
    </li>
    <li>
      <a href="https://education.github.com/discount_requests/new">GitHub for Education</a>
    </li>
    <li class="divider"></li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Code
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="https://github.com/andrewproctor/rminicourse">Course on Github</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Module 6: Intro to Bayesian Methods in R</h1>

</div>


<p><a class="btn btn-primary" href="https://andrewproctor.github.io/rcourse/assets/module6.pdf" role="button">Slides</a> <a class="btn btn-primary" href="https://andrewproctor.github.io/rcourse/assets/exercise-m6.pdf" role="button">Exercise</a></p>
<p><br></p>
<div id="conceptual-introduction" class="section level2">
<h2>Conceptual Introduction</h2>
<p><br></p>
<div id="thought-experiment" class="section level3 tabset tabset-pills">
<h3><strong>Thought Experiment</strong></h3>
<div id="question" class="section level4">
<h4>Question</h4>
<p>Imagine I’m conducting a raffle. I have a large bowl, and inside of it are many raffle entries, each with different numbers on them.</p>
<ul>
<li><p>Let the variable <em>x</em> represent the number drawn from the bowl.</p></li>
<li><p>Before reaching into the bowl, I want to know:</p>
<p><em>‘’What is the probability that I’m going to pick up a number less than 10 from the bowl?’’</em></p></li>
<li><p>That is, what is <span class="math inline">\(p(x \leq 10)\)</span>?</p>
<ul>
<li><strong><em>Does this probability change if I tell you that all the numbers in the bowl have at least 3 digits (ie are <span class="math inline">\(\geq 100\)</span>)?</em></strong></li>
</ul></li>
</ul>
<p><br> <br></p>
</div>
<div id="answer" class="section level4">
<h4>Answer</h4>
<p><strong>Classical Statistics:</strong> <em>No.</em></p>
<ul>
<li><p>Probability is defined as: <span class="math inline">\(\lim_{n \rightarrow \infty} \frac{n_S}{n}\)</span>, where <span class="math inline">\(n\)</span> is the number of times I repeat the experiment and <span class="math inline">\(n_S\)</span> is the number of times a number <span class="math inline">\(x \leq 10\)</span> is drawn.</p></li>
<li><p><span class="math inline">\(p(x \leq 10)\)</span> was always equal to zero, all that changed was your knowledge of the experiment.</p></li>
</ul>
<p><strong>Bayesian Statistics:</strong> <em>Almost certainly.</em></p>
<ul>
<li><p>Probability is a measure of subjective belief about how likely an event is, based on prior understanding and new information.</p></li>
<li><p>Prior <span class="math inline">\(\rightarrow\)</span> Information <span class="math inline">\(\rightarrow\)</span> Posterior</p></li>
</ul>
<p><br> <br></p>
</div>
</div>
<div id="epistomological-difference" class="section level3">
<h3><strong>Epistomological difference</strong></h3>
<ul>
<li><p>Bayesian statistics integrates the epistemological uncertainty of statistical estimation into its core procedures. It’s fundamental goal is to assess and improve the accuracy of one’s beliefs based on a set of identifying statistical assumptions.</p></li>
<li><p>Classical statistics attempts to instead conduct inference on the (unknown) underlying reality, based on its own set of identifying assumptions.</p></li>
</ul>
<p><strong><em>NOT mutually exclusive</em></strong></p>
<p><br></p>
</div>
<div id="bayes-rule" class="section level3">
<h3><strong>Bayes Rule</strong></h3>
<p>The cornerstone of the Bayesian approach (and the source of its name) is the conditional likelihood theorem known as <strong>Bayes’ rule</strong>.</p>
<p>In its simplest form, Bayes’ Rule states that for two events and A and B (with <span class="math inline">\(P(B) \neq 0\)</span>): <span class="math display">\[ P(A|B) = \frac{P(B|A)P(A)}{P(B)} \]</span></p>
<p>Or, if A can take on multiple values, we have the <strong>extended form</strong>:</p>
<p><span class="math display">\[ p(A_i|B) = \frac{p(B | A_i) P(A_i)}{\sum_j P(B|A_j)P(A_j)} \]</span></p>
<p><br></p>
</div>
<div id="inference-using-bayes-rule" class="section level3">
<h3><strong>Inference using Bayes’ Rule</strong></h3>
<p>Adapting Bayes’ Rule to the case of a parameter value, <span class="math inline">\(\theta\)</span> and observed data <em>y</em>, we have:</p>
<p><span class="math display">\[ p(\theta \mid y) = \frac{f(\theta, y)}{f(y)} =  \frac{f(y\mid\theta)p(\theta)}{ \int f(y \mid \theta) p(\theta) d\theta} \underbrace{\propto}_{\text{proportional to}} f(y|\theta)p(\theta) \]</span></p>
<p>Adding a bit of terminology:</p>
<ul>
<li><span class="math inline">\(p(\theta)\)</span> is the <strong>prior</strong> distribution: our initial subjective belief about the probability distribution of <span class="math inline">\(\theta\)</span>.</li>
<li><p><span class="math inline">\(f(y|\theta)\)</span> you may recognize from Maximum Likelihood estimation as:</p>
<ul>
<li><span class="math inline">\(f(y | \theta) = \prod_{i=1}^n f(y_i |\theta) = \mathcal{L} (\theta)\)</span>, the <strong>likelihood function</strong>.</li>
</ul></li>
<li><p>Finally, <span class="math inline">\(p(\theta)|y)\)</span> is our <strong>posterior</strong> (post-experiment) belief     about the probability distribution of <span class="math inline">\(\theta\)</span>.</p></li>
</ul>
<p><span class="math display">\[ \overbrace{p(\theta \mid y)}^{\text{posterior}} = \frac{\overbrace{f(y\mid\theta)}^\text{likelihood} \overbrace{p(\theta)}^\text{prior}}{\underbrace{\int f(y \mid \theta) p(\theta) d\theta}_\text{average likelihood}}  \underbrace{\propto}_{\text{proportional to}} \overbrace{f(y|\theta)}^{likelihood} \overbrace{p(\theta)}^{prior}\]</span></p>
<p>Hence we have the basic statement:</p>
<p><span class="math display">\[ Posterior \propto Likelihood \times Prior \]</span></p>
<ul>
<li>This is commonly summarized as saying that the posterior     belief is a compromise between the data and prior belief.</li>
</ul>
<p><br></p>
</div>
<div id="priors" class="section level3">
<h3><strong>Priors</strong></h3>
<p>Given this <em>compromise with prior beliefs</em>, Bayesian analysis is often attacked as subjective and a lot of emphasis is placed on the role of prior beliefs. <strong>But fear not!</strong></p>
<ul>
<li><p>First, as the data sample increases, the data becomes the determining factor of the posterior probability.</p></li>
<li><p>Moreover, if desired, we can easily specify priors that have <em>no effect</em> on the posterior estimates.</p></li>
</ul>
<p><br></p>
<div id="types-of-priors" class="section level4">
<h4><strong>Types of Priors</strong></h4>
<p>Different types of priors include:</p>
<ul>
<li><p><strong>Uninformative (or “flat”) priors</strong>: Priors that have no impact on posterior values (ie assuming total ignorance about the possible parameter value).</p>
<ul>
<li>A classic uninformative prior is the uniform prior, which treats all possible parameter values as equally likely: <span class="math inline">\(p(\theta) = c \text{ } \forall \theta \in \Theta\)</span></li>
</ul></li>
<li><p><strong>Informative priors</strong>: Priors where we use prior knowledge to specify a prior with a best-guess of the prior mean and distribution for a parameter value.</p></li>
<li><p><strong>Weakly informative</strong> or <strong>regularizing priors</strong>: Priors which are deliberately less informative than our actual knowledge, affecting estimates less than informative priors but at least incorporating <em>very conservative</em> information into the    production of posterior estimates.</p></li>
</ul>
<p><br></p>
</div>
<div id="intuition-about-priors" class="section level4">
<h4><strong>Intuition about priors</strong></h4>
<p>Think for instance of inference about possible life expectancy:</p>
<ul>
<li><p>We could specify an uninformative prior that says allows for any possible lifespan (even living to 1 million years old).</p></li>
<li><p>We could specify some skewed normal distribution that approximates our current estimates of the distribution of current lifespans.</p></li>
<li><p>Or we could specify some weaker prior that for instance allows life expectancy to be more dispersed and ages to reach, say 150 or 200 years old.</p>
<ul>
<li>Weakly informative priors don’t use our best understanding of life expectancy, but at least “tells” our analysis that some possibilities are very implausible.</li>
</ul></li>
</ul>
<p><strong><em>In almost all circumstances, a weak prior should be preferred.</em></strong></p>
<p><br></p>
</div>
<div id="priors-example" class="section level4">
<h4><strong>Priors Example:</strong></h4>
<div class="figure">
<img src="priors.png" alt="From van de Schoot et al 2014" />
<p class="caption">From van de Schoot et al 2014</p>
</div>
<p><br> <br></p>
</div>
</div>
<div id="bayesian-computation" class="section level3">
<h3><strong>Bayesian Computation</strong></h3>
<p>One major feature of Bayesian inference that I haven’t mentioned so far is the intractability of analytic solutions for estimating posterior distributions in most circumstances.</p>
<p>Recall: <span class="math display">\[ p(\theta \mid y) = \frac{f(\theta, y)}{f(y)} =  \frac{f(y\mid\theta)p(\theta)}{ \int f(y \mid \theta) p(\theta) d\theta} \]</span></p>
<p>For models that are more complex or that involve high-dimensional data, closed-form solutions are not available for the integral in the denominator.</p>
<p>Hence, Bayesian analysis instead typically relies on numerical methods, usually Markov Chain Monte Carlo (MCMC) methods.</p>
<p><br></p>
<div id="mcmc-methods" class="section level4">
<h4><strong>MCMC Methods</strong></h4>
<p>This method relies on sequentially sampling values of <span class="math inline">\(\theta\)</span> from an approximation of the posterior distribution and then correcting the approximation to create better subsequent samples.</p>
<ul>
<li><p>Because the approximated distribution used in 1 step relies on the sample from the previous step, the simulation forms a <strong>Markov chain</strong>.</p></li>
<li><p>A critical property then is <strong>convergence</strong>: Have our simulations converged to the real target distribution?</p>
<ul>
<li>Typically instead of running one really long “chain”, researchers use multiple short chains.<br />
</li>
<li>The aggregate can not only converge faster, but can provide a better sense of convergence through the noisiness between multiple chains.</li>
</ul></li>
</ul>
<p><br></p>
</div>
</div>
<div id="hypothesis-testing-in-bayesian-analysis" class="section level3">
<h3><strong>Hypothesis Testing in Bayesian Analysis?</strong></h3>
<p>Another point of divergence for Bayesian vs. frequentist data analysis is even more dramatic:</p>
<ul>
<li><p>Largely, there is no place for null-hypothesis significance testing (NHST) in Bayesian analysis</p>
<ul>
<li><p>Bayesian analysis has <em>something</em> similar called a <strong>Bayes’ factor</strong>, which essentially assigns a prior probability to the likilihood ratio of a null and alternative model and then estimates it’s posterior probability.</p></li>
<li><p>But Bayes factors are heavily criticized by leading Bayesians like Andrew Gelman and Donald Rubin, because it is highly sensitive to prior probabilities and model structures, among other issues.</p></li>
</ul></li>
<li><p>Instead, analysis is oriented around estimation of the posterior distribution of parameters (or predictions).</p></li>
</ul>
<p><br></p>
<div id="bayesian-inference-with-credible-intervals" class="section level4">
<h4><strong>Bayesian Inference with Credible Intervals</strong></h4>
<p>Without NHST to tell us if our results are significant, does that mean we just get point estimates and no way to assess how reliable they are? <strong><em>No!</em></strong></p>
<ul>
<li><p>Recall that we are estimating the posterior <em>distribution</em> of a parameter (or predicted outcome).</p></li>
<li><p>Hence, we can easily produce a 95% interval for the parameter, simply using the quantiles of the posterior CDF.</p></li>
</ul>
<p>In Bayesian analysis, we replace the 100(<span class="math inline">\(1-\alpha\)</span>)% frequentist confidence interval with the 100(<span class="math inline">\(1-\alpha\)</span>)% <strong>credible interval</strong>.</p>
<p>A credible interval, however, has a much more appealing interpretation than a confidence interval.</p>
<ul>
<li><p>A confidence interval has the interpretation that, in repeated samples, the true parameter lies within the confidence region 95% of the time.</p></li>
<li><p>A credible interval is what people <em>think</em> a confidence interval should mean: there is a 95% chance that the true value lies within the 95% credible interval.</p></li>
</ul>
<p><br></p>
</div>
</div>
</div>
<div id="bayesian-regression-with-rstanarm" class="section level2">
<h2>Bayesian Regression with rstanarm</h2>
<div id="stan" class="section level3">
<h3><strong>Stan</strong></h3>
<p>Probably the best approach to doing Bayesian analysis in any software environment is with <a href="https://www.rdocumentation.org/packages/rstan">rstan</a>, which is an R interface to the Stan programming language designed for Bayesian analysis.</p>
<ul>
<li><p>To use <a href="https://www.rdocumentation.org/packages/rstan">rstan</a>, you will first need to install <strong>RTools</strong> from <a href="https://github.com/stan-dev/rstan/wiki/Installing-RStan-on-Windows">this link</a>.</p></li>
<li><p>Then install the package <a href="https://www.rdocumentation.org/packages/rstan">rstan</a> from RStudio (make sure to set <code>dependencies=TRUE</code> when installing).</p></li>
</ul>
<p><br></p>
<div id="parallelization-support" class="section level4">
<h4><strong>Parallelization support</strong></h4>
<p>Once you’ve setup <a href="https://www.rdocumentation.org/packages/rstan">rstan</a>, there is one more thing you should typically do: tell it to run on multiple cores.</p>
<ul>
<li>rstan includes support for basic parallelization that speeds up execution tremendous for larger / more complex regressions.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(rstan)
<span class="kw">rstan_options</span> (<span class="dt">auto_write=</span><span class="ot">TRUE</span>)
<span class="co"># Run on multiple cores</span>
<span class="kw">options</span> (<span class="dt">mc.cores=</span>parallel<span class="op">::</span><span class="kw">detectCores</span> ()) </code></pre></div>
<p><br></p>
</div>
<div id="a-stan-regression-example" class="section level4">
<h4><strong>A Stan regression example</strong></h4>
<p>Now that you’re <strong><em>hopefully</em></strong> excited about rstan, let’s look at an example of a rstan regression from the package documentation:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Create schools.stan --------------------------</span>
data {
  int<span class="op">&lt;</span>lower=<span class="dv">0</span><span class="op">&gt;</span><span class="st"> </span>J;       <span class="op">/</span><span class="er">/</span><span class="st"> </span>number of schools 
  real y[J];            <span class="op">/</span><span class="er">/</span><span class="st"> </span>estimated treatment effects
  real<span class="op">&lt;</span>lower=<span class="dv">0</span><span class="op">&gt;</span><span class="st"> </span>sigma[J]; <span class="op">/</span><span class="er">/</span><span class="st"> </span>s.e. of effect estimates 
}
parameters {
  real mu; 
  real<span class="op">&lt;</span>lower=<span class="dv">0</span><span class="op">&gt;</span><span class="st"> </span>tau;
  vector[J] eta;
}

## Still creating schools.stan
transformed parameters {
  vector[J] theta;
  theta =<span class="st"> </span>mu <span class="op">+</span><span class="st"> </span>tau <span class="op">*</span><span class="st"> </span>eta;
}

model {
  target <span class="op">+</span><span class="er">=</span><span class="st"> </span><span class="kw">normal_lpdf</span>(eta <span class="op">|</span><span class="st"> </span><span class="dv">0</span>, <span class="dv">1</span>);
  target <span class="op">+</span><span class="er">=</span><span class="st"> </span><span class="kw">normal_lpdf</span>(y <span class="op">|</span><span class="st"> </span>theta, sigma);
}
<span class="co"># End of schools.stan --------------------------</span>

## Run Stan regression using schools.stan
fit1 &lt;-<span class="st"> </span><span class="kw">stan</span>(
  <span class="dt">file =</span> <span class="st">&quot;schools.stan&quot;</span>, <span class="co"># Stan program</span>
  <span class="dt">data =</span> schools_data,    <span class="co"># named list of data</span>
  <span class="dt">chains =</span> <span class="dv">4</span>,             <span class="co"># number of Markov chains</span>
  <span class="dt">warmup =</span> <span class="dv">1000</span>,          <span class="co"># number of warmup iterations per chain</span>
  <span class="dt">iter =</span> <span class="dv">2000</span>,            <span class="co"># total number of iterations per chain</span>
  <span class="dt">cores =</span> <span class="dv">2</span>,              <span class="co"># number of cores (using 2 just for the vignette)</span>
  <span class="dt">refresh =</span> <span class="dv">1000</span>          <span class="co"># show progress every &#39;refresh&#39; iterations</span>
  )</code></pre></div>
<p><br></p>
</div>
</div>
<div id="rstanarm-making-rstan-easy" class="section level3">
<h3><strong>Rstanarm: making RStan easy</strong></h3>
<p><strong><em>Oops! That was a lot of code!</em></strong> And there’s still a bit more left out. Luckily, there are a couple of packages that exist to make your life easier:</p>
<ul>
<li><p>First, there is <a href="https://www.rdocumentation.org/packages/rstanarm">rstanarm</a>, which was created by the developers of Stan and rstan to make running a Bayesian regression with rstan much more like you would run a normal frequentist regression.</p></li>
<li><p>Another very similar package to rstanarm is <a href="https://www.rdocumentation.org/packages/brms">brms</a>, which also makes running Bayesian regression much simpler and ‘R-like’.</p></li>
</ul>
<p><br></p>
<div id="short-comparison-of-rstanarm-and-brms" class="section level4">
<h4><strong>Short comparison of rstanarm and brms</strong></h4>
<p><strong>rstanarm</strong> is faster, has better posterior checking, and is a bit simpler to use.</p>
<p><strong>brms</strong> is generally a bit more flexible, with support for some regression types missing in rstanarm, more flexible specification of priors, and support for more types of error correlational structures.</p>
<ul>
<li>My sense is that <a href="https://www.rdocumentation.org/packages/rstanarm">rstanarm</a> is the more popular choice, so that’s what we’ll use here.</li>
</ul>
<p><br></p>
</div>
<div id="using-rstanarm" class="section level4">
<h4><strong>Using rstanarm</strong></h4>
<p>With rstanarm, most regressions you run using the function <a href="https://www.rdocumentation.org/packages/rstanarm/versions/2.17.2/topics/stan_glm">stan_glm()</a></p>
<ul>
<li>Since generalized linear models (GLMs) incorporates models like linear regression, probit, logit, Poisson, binomial, exponential, etc)</li>
</ul>
<p><strong>Syntax:</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mybayesreg &lt;-<span class="st"> </span><span class="kw">stan_glm</span>(y <span class="op">~</span><span class="st"> </span>X1 <span class="op">+</span><span class="st"> </span>x2 <span class="op">+</span><span class="st"> </span>x3 ..., 
                       <span class="dt">family =</span> myfamily, <span class="dt">data =</span> mydata, 
                       <span class="dt">prior =</span> myprior)</code></pre></div>
<p><br></p>
</div>
<div id="options-with-stan_glm" class="section level4">
<h4><strong>Options with stan_glm</strong></h4>
<p><strong>Family</strong> (with a possible <strong>link</strong> argument needed as well) defines the type of regression you want:</p>
<ul>
<li>Linear regression: <code>family = gaussian</code></li>
<li>Logit: <code>family = binomial(link = &quot;logit&quot;)</code></li>
<li>Probit: <code>family = binomial(link = &quot;probit&quot;)</code></li>
<li>Poisson: <code>family = poisson</code></li>
<li>More options can be read from the main <a href="https://www.rdocumentation.org/packages/stats/versions/3.4.3/topics/glm">GLM page</a></li>
</ul>
<p><strong>Prior distributions:</strong></p>
<ul>
<li><strong>Flat priors</strong> can be set by using <code>prior = NULL</code></li>
<li><p><em>[Weakly]</em> Informative Priors can be specified by using <code>prior =</code> with one of:</p>
<ul>
<li><em>normal, student_t, cauchy, laplace</em> and more found <a href="https://www.rdocumentation.org/packages/rstanarm/versions/2.17.2/topics/priors">here</a></li>
</ul></li>
</ul>
<p><br></p>
</div>
<div id="a-titanic-survival-example-with-rstanarm" class="section level4">
<h4><strong>A Titanic survival example with rstanarm</strong></h4>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(Titanic)
<span class="co"># Display titanic data</span>
<span class="kw">glimpse</span>(Titanic,<span class="dt">width =</span> <span class="dv">50</span>)</code></pre></div>
<pre><code>## Observations: 1,313
## Variables: 6
## $ Name     &lt;fct&gt; &quot;Allen, Miss Elisabeth Walton&quot;…
## $ PClass   &lt;fct&gt; 1st, 1st, 1st, 1st, 1st, 1st, …
## $ Age      &lt;dbl&gt; 29.00, 2.00, 30.00, 25.00, 0.9…
## $ Sex      &lt;fct&gt; female, female, male, female, …
## $ Survived &lt;int&gt; 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, …
## $ SexCode  &lt;int&gt; 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, …</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Reformat Class</span>
Titanic<span class="op">$</span>class &lt;-<span class="st"> </span><span class="kw">str_extract</span>(Titanic<span class="op">$</span>PClass, <span class="st">&quot;[0-9]&quot;</span>)

TitanicLinear &lt;-<span class="st"> </span><span class="kw">stan_glm</span>(Survived <span class="op">~</span><span class="st"> </span>Age <span class="op">+</span><span class="st"> </span>
<span class="st">    </span>SexCode <span class="op">+</span><span class="st"> </span><span class="kw">as.factor</span>(class), 
    <span class="dt">data =</span> Titanic, <span class="dt">family =</span> gaussian)

<span class="kw">summary</span>(TitanicLinear)</code></pre></div>
<pre><code>## 
## Model Info:
## 
##  function:     stan_glm
##  family:       gaussian [identity]
##  formula:      Survived ~ Age + SexCode + as.factor(class)
##  algorithm:    sampling
##  priors:       see help(&#39;prior_summary&#39;)
##  sample:       4000 (posterior sample size)
##  observations: 756
##  predictors:   5
## 
## Estimates:
##                     mean   sd     2.5%   25%    50%    75%    97.5%
## (Intercept)          0.6    0.1    0.5    0.6    0.6    0.7    0.7 
## Age                  0.0    0.0    0.0    0.0    0.0    0.0    0.0 
## SexCode              0.5    0.0    0.4    0.5    0.5    0.5    0.6 
## as.factor(class)2   -0.2    0.0   -0.3   -0.2   -0.2   -0.2   -0.1 
## as.factor(class)3   -0.4    0.0   -0.5   -0.4   -0.4   -0.4   -0.3 
## sigma                0.4    0.0    0.4    0.4    0.4    0.4    0.4 
## mean_PPD             0.4    0.0    0.4    0.4    0.4    0.4    0.5 
## log-posterior     -364.8    1.7 -368.9 -365.7 -364.5 -363.6 -362.5 
## 
## Diagnostics:
##                   mcse Rhat n_eff
## (Intercept)       0.0  1.0  2294 
## Age               0.0  1.0  3168 
## SexCode           0.0  1.0  3953 
## as.factor(class)2 0.0  1.0  2815 
## as.factor(class)3 0.0  1.0  2502 
## sigma             0.0  1.0  4174 
## mean_PPD          0.0  1.0  3765 
## log-posterior     0.0  1.0  1837 
## 
## For each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).</code></pre>
<p><br> <br></p>
</div>
</div>
<div id="credible-intervals" class="section level3">
<h3><strong>Credible intervals</strong></h3>
<p>You can also easily get print the credible intervals with the function <a href="https://www.rdocumentation.org/packages/rstanarm/versions/2.17.2/topics/posterior_interval.stanreg">posterior_interval()</a></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">posterior_interval</span>(TitanicLinear, <span class="dt">prob=</span><span class="fl">0.95</span>)</code></pre></div>
<pre><code>##                           2.5%        97.5%
## (Intercept)        0.524131299  0.733029097
## Age               -0.008178664 -0.003942273
## SexCode            0.443016245  0.561969161
## as.factor(class)2 -0.283879669 -0.133217453
## as.factor(class)3 -0.467082496 -0.318925289
## sigma              0.369328091  0.408310633</code></pre>
<div id="graphical-credible-intervals" class="section level4">
<h4><strong>Graphical credible intervals</strong></h4>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(TitanicLinear)</code></pre></div>
<p><img src="module6_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p><br> <br></p>
</div>
</div>
<div id="plotting-the-posterior-distribution" class="section level3">
<h3><strong>Plotting the posterior distribution</strong></h3>
<p>You can also easily plot the posterior distribution of a parameter in R.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Titanic_posterior &lt;-<span class="st"> </span>TitanicLinear <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">rename</span>(<span class="dt">sec.class =</span> <span class="st">&quot;as.factor(class)2&quot;</span>,
         <span class="dt">third.class =</span> <span class="st">&quot;as.factor(class)3&quot;</span>)

<span class="kw">ggplot</span>(Titanic_posterior, <span class="kw">aes</span>(<span class="dt">x=</span>third.class)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_histogram</span>()</code></pre></div>
<p><img src="module6_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p><br></p>
<div id="juxtaposing-the-prior-and-the-posterior" class="section level4">
<h4><strong>Juxtaposing the prior and the posterior</strong></h4>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">posterior_vs_prior</span>(TitanicLinear)</code></pre></div>
<p><img src="module6_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p><br></p>
</div>
</div>
</div>
<div id="model-testing" class="section level2">
<h2>Model Testing</h2>
<div id="model-testing-basics" class="section level3">
<h3><strong>Model testing basics</strong></h3>
<p>There are a number of different regression diagnostics after performing Bayesian regression to help infer if the model converged, how well it performs, and even compare between models.</p>
<p>Today, we’ll cover some of them included with rstanarm as well as the very useful <a href="https://www.rdocumentation.org/packages/shinystan">shinystan package</a>.</p>
<p><br></p>
</div>
<div id="graphical-posterior-predictive-analysis" class="section level3">
<h3><strong>Graphical posterior predictive analysis</strong></h3>
<p>To check the predictive accuracy of the posterior distribution, you can use the function <a href="https://www.rdocumentation.org/packages/rstanarm/versions/2.17.2/topics/pp_check.stanreg">pp_check()</a>, which plots simulated y values from the posterior distribution against the actual values of y.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pp_check</span>(TitanicLinear)</code></pre></div>
<p><img src="module6_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<p><br> <br></p>
</div>
<div id="regularization-and-predictive-accuracy" class="section level3">
<h3><strong>Regularization and Predictive Accuracy</strong></h3>
<p>A critical issue in both Bayesian and frequentist estimation is how to balance predictive accuracy with parsimony. Put another, the researcher should be concerned with not overfitting the data while still creating a compelling model.</p>
<p>The basic approach in frequentist method is to use the Akaike information criterion (AIC):</p>
<p><strong>Expected Log Predictive Density:</strong> <span class="math display">\[\hat{elpd}_{AIC}  =  \log p(y | \hat{\theta}_{MLE}) - k\]</span></p>
<ul>
<li>Where <span class="math inline">\(\theta_{MLE}\)</span> is the maximum likelihood estimator of <span class="math inline">\(\theta\)</span>,</li>
<li><span class="math inline">\(\log p(y | \hat{\theta}_{MLE})\)</span> is the log likelihood given <span class="math inline">\(\theta_{MLE}\)</span>,</li>
<li>and k is the number of parameters in the model.</li>
</ul>
<p><br></p>
<div id="deviance-information-criterion" class="section level4">
<h4><strong>Deviance information criterion</strong></h4>
<p>The most basic Bayesian adaptation of the AIC is the Deviance information criterion (DIC):</p>
<p><span class="math display">\[\hat{elpd}_{DIC}  =  \log p(y | \hat{\theta}_{Bayes}) - p_{DIC}\]</span></p>
<ul>
<li>Where <span class="math inline">\(\theta_{Bayes}\)</span> is the mean posterior estimate and</li>
<li><span class="math inline">\(p_{DIC}\)</span> is the number of “effective parameters in the model” using a data-biased correction</li>
</ul>
<p><br></p>
</div>
<div id="watanabe-akaike-information-criterion" class="section level4">
<h4><strong>Watanabe-Akaike information criterion</strong></h4>
<p>An improvement over the DIC is the Watanabe-Akaike information criterion:</p>
<p><span class="math display">\[\hat{elpd}_{WAIC} = \sum_{i=1}^{n} \log p(y_i) - \sum_{i=1}^{n} \log V \Big[p(y_i) \Big]\]</span></p>
<p>The WAIC has the advantages of:</p>
<ul>
<li><p>Averaging the likelihood over the posterior distribution rather than using the mean</p></li>
<li><p>Does not assume a multivariate Gaussian posterior distribution, as does the DIC (and AIC)</p></li>
</ul>
<p><br></p>
<div id="waic-example" class="section level5">
<h5><strong>WAIC example</strong></h5>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">waic</span>(TitanicLinear)</code></pre></div>
<pre><code>## 
## Computed from 4000 by 756 log-likelihood matrix
## 
##           Estimate   SE
## elpd_waic   -360.5 19.4
## p_waic         6.1  0.3
## waic         721.0 38.7</code></pre>
<p><br></p>
</div>
</div>
<div id="leave-one-out-cross-validation" class="section level4">
<h4><strong>Leave One Out Cross-Validation</strong></h4>
<p>Another method alongside WAIC for comparing out-of-sample predictive ability is to apply leave-one-out cross-validation (LOO).</p>
<ul>
<li>LOO assesses predictive ability of posterior simulations in which the data is iteratively partitioned into training and prediction sets.</li>
</ul>
<p><strong>Expected Log Predictive Density:</strong><br />
<span class="math display">\[\hat{elpd}_{LOO} = \sum_{i=1}^{n} \log p(y_i | y_{-i})\]</span></p>
<div id="loo-example" class="section level5">
<h5><strong>LOO example</strong></h5>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">loo</span>(TitanicLinear)</code></pre></div>
<pre><code>## 
## Computed from 4000 by 756 log-likelihood matrix
## 
##          Estimate   SE
## elpd_loo   -360.5 19.4
## p_loo         6.1  0.3
## looic       721.0 38.7
## ------
## Monte Carlo SE of elpd_loo is 0.0.
## 
## All Pareto k estimates are good (k &lt; 0.5).
## See help(&#39;pareto-k-diagnostic&#39;) for details.</code></pre>
<p><br></p>
</div>
</div>
<div id="comparing-models" class="section level4">
<h4><strong>Comparing models</strong></h4>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Titanic_probit &lt;-<span class="st"> </span><span class="kw">stan_glm</span>(Survived <span class="op">~</span><span class="st"> </span>Age <span class="op">+</span><span class="st"> </span>
<span class="st">    </span>SexCode <span class="op">+</span><span class="st"> </span><span class="kw">as.factor</span>(class), 
    <span class="dt">data =</span> Titanic, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link=</span>probit))
Loo_probit &lt;-<span class="st"> </span><span class="kw">loo</span>(Titanic_probit)

Titanic_logit &lt;-<span class="st"> </span><span class="kw">stan_glm</span>(Survived <span class="op">~</span><span class="st"> </span>Age <span class="op">+</span><span class="st"> </span>
<span class="st">    </span>SexCode <span class="op">+</span><span class="st"> </span><span class="kw">as.factor</span>(class), 
    <span class="dt">data =</span> Titanic, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link=</span>logit))
Loo_logit &lt;-<span class="st"> </span><span class="kw">loo</span>(Titanic_logit)

<span class="co"># ELPD_diff&gt;0 indicates more support for 2nd model</span>
<span class="kw">compare_models</span>(Loo_probit, Loo_logit)</code></pre></div>
<pre><code>## 
## Model comparison: 
## (negative &#39;elpd_diff&#39; favors 1st model, positive favors 2nd) 
## 
## elpd_diff        se 
##       1.2       0.8</code></pre>
<p><br></p>
</div>
<div id="many-more-diagnostics-with-shinystan" class="section level4">
<h4><strong>Many more diagnostics with shinystan</strong></h4>
<p>Probably the most popular diagnostic for Bayesian regression in R is the functionality from the <a href="https://www.rdocumentation.org/packages/shinystan">shinystan package</a>.</p>
<ul>
<li>Shinystan launches a “Shiny” web application to show you model diagnostics, so it can’t be done inside of a RMarkdown document (but works just fine if called from the console.)</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Do in console not RMarkdown</span>
<span class="kw">launch_shinystan</span>(TitanicLinear)</code></pre></div>
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
