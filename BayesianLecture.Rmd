---
title: "Intro to Bayesian Methods"
author: "Andrew Proctor"
date: "March 2018"
output:
  html_document:
    df_print: paged
    highlight: haddock
    theme: flatly
    toc: yes
    toc_float:
      collapsed: no
  html_notebook:
    highlight: haddock
    theme: flatly
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(rio)
library(tidyverse)
```
## Conceptual Introduction

### A Thought Experiment {.tabset}


#### Question

- Imagine I'm conducting a raffle lottery.  I have a large bowl, and inside of it are many raffle entries, each with different numbers on them.  
- Let the variable $x$ represent the number drawn from the bowl.  

- Before reaching into the bowl, I want to know: 
    *''What is the probability that I'm going to pick up a number less than 10 from the bowl,''* ...
  That is, what is $p(x \leq 10)$?

  + Does this probability change if I tell you that all the numbers in the bowl have at least 3 digits (ie $\geq 100$)?

#### Answer

**Classical Statistics:** No. 

- Probability is defined as:  $\lim_{n \rightarrow \infty} \frac{n_S}{n}$, where $n$ is the number of times I repeat the experiment and $n_S$ is the number of times a number $x \leq 10$ is drawn.

- $p(x \leq 10)$ was always equal to zero, all that change was your knowledge of the experiment.

**Bayesian Statistics:** Almost certainly. 

-  Probability is a measure of subjective belief about how likely an event is, based on prior understanding and new information.
  
  + Prior $\rightarrow$ Information $\rightarrow$ Posterior
    
### Epistomological difference 
- Bayesian statistics integrates the epistemological uncertainty of statistical estimation into its core procedures.  It's fundamental goal is to assess and improve the accuracy of one's beliefs based on a set of identifying statistical assumptions.

- Classical statistics attempts to instead conduct inference on the (unknown) underlying reality, based on its own set of identifying assumptions.

** NOT mutually exclusive **

## Bayesian Methods in R


### Installation

First, you will need to install **RStan** and **RTools** from [this link](https://github.com/stan-dev/rstan/wiki/Installing-RStan-on-Windows).

Then install the **rstan** and **rstanarm** packages.

```{r, eval=FALSE}
# Run only once
install.packages("rstan", repos = "https://cloud.r-project.org/", dependencies=TRUE)

install.packages("rstanarm", dependencies=TRUE)

```

### Initialize the Packages

```{r, message=FALSE,warning=FALSE}
library(rstan)

rstan_options (auto_write=TRUE)
options (mc.cores=parallel::detectCores ()) # Run on multiple cores

library(rstanarm)
library(tidyverse)

```

### Load Data

First, we load the dataset using the **rio** package.

```{r cars}
#PISA2015 <- import("cy6_ms_cmb_stu_qqq.sas7bdat") %>% filter(CNT == "SWE")
#glimpse(PISA2015)

#install.packages("titanic")

```

### Data Wrangling


```{r}
titanic <- import("https://raw.githubusercontent.com/vincentarelbundock/Rdatasets/master/csv/datasets/Titanic.csv")
# Display titanic data
titanic


# Recode Class
titanic$class  <- recode(titanic$PClass, "*"="NA", "1st"="1", "2nd"="2", "3rd"="3")
titanic$class [titanic$class == "NA"] <- NA
titanic$class <- as.numeric(titanic$class)


```

### Bayesian Regression

```{r, message=FALSE}

TitanicGLMbasic <- stan_glm(Survived ~ Age + SexCode  + as.factor(class), data = titanic, family = gaussian())


```

### Inference
```{r}
summary(TitanicGLMbasic)
plot(TitanicGLMbasic)

```

### Test test test
```{r}
 #launch_shinystan(TitanicGLMbasic)

```
